{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project description\n",
    "\n",
    "This project tries to train a model to predict if a student can be admitted to a graduate school based on features including GPA, GRE score and undergraduate school ranks. \n",
    "\n",
    "The source dataset can be found at  https://stats.idre.ucla.edu/stat/data/binary.csv\n",
    "\n",
    "This problem was originally presented in Udacity. I found it was a perfect fit for myself to practice the basic techniques, such as data pre-preparation, define model, loss function, and gradient descent method to minimize loss function. \n",
    "\n",
    "Solution: multiple layer model including one hidden layer. Overall structure is similar to the single layer model.\n",
    "\n",
    "* build a network with one hidden layer and one output layer\n",
    "* use sigmoid function as output activation function\n",
    "* use MSE (mean square error) as the loss function\n",
    "* use gradient descent method to minimize the loss function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) load dataset and pre-processing\n",
    "\n",
    "### load data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv data using pandas\n",
    "admissions = pd.read_csv('binary.csv')\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-processing data\n",
    "\n",
    "* **make dummy variables for rank**\n",
    "\n",
    "(1) **pandas.get_dummies**(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "Convert categorical variable into dummy/indicator variables\n",
    "\n",
    "*Parameters*:\t\n",
    "**data** : array-like, Series, or DataFrame\n",
    "\n",
    "**prefix** : string, list of strings, or dict of strings, default None\n",
    "String to append DataFrame column names Pass a list with length equal to the number of columns when calling get_dummies on a DataFrame. Alternatively, prefix can be a dictionary mapping column names to prefixes.\n",
    "\n",
    "**prefix_sep** : string, default ‘_’\n",
    "\n",
    "*Returns*\n",
    "**dummies** : DataFrame or SparseDataFrame\n",
    "\n",
    "(2) **concatenate objects along a particular axis with optional set logic along the other axes **\n",
    "\n",
    "**pandas.concat**(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "**objs** : a sequence or mapping of Series, DataFrame, or Panel objects\n",
    "If a dict is passed, the sorted keys will be used as the keys argument, unless it is passed, in which case the values will be selected (see below). Any None objects will be dropped silently unless they are all None in which case a ValueError will be raised\n",
    "\n",
    "**axis** : {0/’index’, 1/’columns’}, default 0\n",
    "The axis to concatenate along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- print admissions['rank'] = [index, rank] ----\n",
      "0    3\n",
      "1    3\n",
      "2    1\n",
      "3    4\n",
      "4    4\n",
      "Name: rank, dtype: int64\n",
      "---- After pd.get_dummies operation -----\n",
      "   rank_1  rank_2  rank_3  rank_4\n",
      "0       0       0       1       0\n",
      "1       0       0       1       0\n",
      "2       1       0       0       0\n",
      "3       0       0       0       1\n",
      "4       0       0       0       1\n",
      "--- data after concat ----\n",
      "   admit  gre   gpa  rank  rank_1  rank_2  rank_3  rank_4\n",
      "0      0  380  3.61     3       0       0       1       0\n",
      "1      1  660  3.67     3       0       0       1       0\n",
      "2      1  800  4.00     1       1       0       0       0\n",
      "3      1  640  3.19     4       0       0       0       1\n",
      "4      0  520  2.93     4       0       0       0       1\n"
     ]
    }
   ],
   "source": [
    "# Make dummy variables for rank\n",
    "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "\n",
    "print(\"---- print admissions['rank'] = [index, rank] ----\")\n",
    "print(admissions['rank'].head())\n",
    "\n",
    "print(\"---- After pd.get_dummies operation -----\")\n",
    "print(pd.get_dummies(admissions['rank'], prefix='rank').head())\n",
    "\n",
    "print(\"--- data after concat ----\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **remove the redundant column of \"rank\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
      "0      0  380  3.61       0       0       1       0\n",
      "1      1  660  3.67       0       0       1       0\n",
      "2      1  800  4.00       1       0       0       0\n",
      "3      1  640  3.19       0       0       0       1\n",
      "4      0  520  2.93       0       0       0       1\n"
     ]
    }
   ],
   "source": [
    "data = data.drop('rank', axis=1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **standarize features - scaling **\n",
    "\n",
    "DataFrame.loc\n",
    "\n",
    "Purely label-location based indexer for selection by label.\n",
    "\n",
    ".loc[ ] is primarily label based, but may also be used with a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- before scaling ----\n",
      "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
      "0      0  380  3.61       0       0       1       0\n",
      "1      1  660  3.67       0       0       1       0\n",
      "2      1  800  4.00       1       0       0       0\n",
      "3      1  640  3.19       0       0       0       1\n",
      "4      0  520  2.93       0       0       0       1\n",
      "---- after scaling ----\n",
      "   admit       gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
      "0      0 -1.798011  0.578348       0       0       1       0\n",
      "1      1  0.625884  0.736008       0       0       1       0\n",
      "2      1  1.837832  1.603135       1       0       0       0\n",
      "3      1  0.452749 -0.525269       0       0       0       1\n",
      "4      0 -0.586063 -1.208461       0       0       0       1\n"
     ]
    }
   ],
   "source": [
    "# Standarize features\n",
    "print(\"---- before scaling ----\")\n",
    "print(data.head())\n",
    "\n",
    "for field in ['gre', 'gpa']:\n",
    "    mean, std = data[field].mean(), data[field].std()\n",
    "    #print(data[field].head())\n",
    "    #print(mean, std)\n",
    "    data.loc[:,field]  = data.loc[:,field].apply(lambda x: (x - mean) / std)\n",
    "\n",
    "print(\"---- after scaling ----\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **split off random 10% of dataset for testing **\n",
    "\n",
    "\n",
    "(1) **numpy.random.choice(a, size=None, replace=True, p=None)**\n",
    "Generates a random sample from a given 1-D array\n",
    "\n",
    "*Parameters*:\n",
    "\n",
    "**a** : 1-D array-like or int\n",
    "If an ndarray, a random sample is generated from its elements. If an int, the random sample is generated as if a were np.arange(a)\n",
    "\n",
    "**size** : int or tuple of ints, optional\n",
    "Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. Default is None, in which case a single value is returned.\n",
    "\n",
    "**replace** : boolean, optional\n",
    "Whether the sample is with or without replacement\n",
    "\n",
    "**p** : 1-D array-like, optional\n",
    "The probabilities associated with each entry in a. If not given the sample assumes a uniform distribution over all entries in a.\n",
    "\n",
    "*Returns*:\t\n",
    "**samples** : single item or ndarray; The generated random samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate index of 90% dataset randomly as training data; the rest is testing data\n",
    "sample = np.random.choice(data.index, size=int(len(data)*0.9), replace=False)\n",
    "# split data set into two subset: data is training set, and test_data is testing set\n",
    "data, test_data = data.loc[sample], data.drop(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **split into features and labels **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, targets = data.drop('admit', axis=1), data['admit']\n",
    "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) define model, loss function\n",
    "\n",
    "\n",
    "* **activation function**: sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **model**: two layer network model including one hidden layer and one output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of hidden units\n",
    "n_hidden = 2  \n",
    "# size of samples and features\n",
    "n_records, n_features = features.shape\n",
    "# Initialize weights\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5, size=(n_features, n_hidden))\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5, size=n_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) gradient descent method to minimize error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html\n",
    "<img src=\"multi_layer.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html\n",
    "<img src=\"IMG_0061.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train loss: ', 0.2749080607365611)\n",
      "('Train loss: ', 0.2509960178261504)\n",
      "('Train loss: ', 0.23721654305876033)\n",
      "('Train loss: ', 0.22924425059725057)\n",
      "('Train loss: ', 0.22452702299851898)\n",
      "('Train loss: ', 0.22166672955258432)\n",
      "('Train loss: ', 0.21990079149158745)\n",
      "('Train loss: ', 0.21880337124388266)\n",
      "('Train loss: ', 0.21812836446731096)\n",
      "('Train loss: ', 0.21772801585043022)\n"
     ]
    }
   ],
   "source": [
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.1\n",
    "last_loss = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        ## Forward pass ##\n",
    "        # TODO: Calculate the output\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output = sigmoid(np.dot(hidden_output, weights_hidden_output))\n",
    "\n",
    "        ## Backward pass ##\n",
    "        # TODO: Calculate the error\n",
    "        error = y - output\n",
    "\n",
    "        # TODO: Calculate error gradient in output unit\n",
    "        output_error = error * output * ( 1 - output )\n",
    "\n",
    "        # TODO: propagate errors to hidden layer\n",
    "        hidden_error = np.dot(output_error, weights_hidden_output) * hidden_output * ( 1 - hidden_output )\n",
    "\n",
    "        # TODO: Update the change in weights\n",
    "        del_w_hidden_output += output_error * hidden_output\n",
    "        del_w_input_hidden += hidden_error * x[:, None]\n",
    "\n",
    "    # TODO: Update weights\n",
    "    weights_input_hidden += learnrate * del_w_input_hidden / n_records\n",
    "    weights_hidden_output += learnrate * del_w_hidden_output / n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) calculate accuracy on testing dataset\n",
    "\n",
    "assume accuracy > 0.5 is good. That means our model should predict correctly on 50% samples of the testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.700\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test data\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
