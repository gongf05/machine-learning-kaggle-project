{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project description\n",
    "\n",
    "This project tries to train a model to predict if a student can be admitted to a graduate school based on features including GPA, GRE score and undergraduate school ranks. \n",
    "\n",
    "The source dataset can be found at  https://stats.idre.ucla.edu/stat/data/binary.csv\n",
    "\n",
    "This problem was originally presented in Udacity. I found it was a perfect fit for myself to practice the basic techniques, such as data pre-preparation, define model, loss function, and gradient descent method to minimize loss function. \n",
    "\n",
    "Solution: single layer model\n",
    "\n",
    "* build a network with one output layer\n",
    "* use sigmoid function as output activation function\n",
    "* use MSE (mean square error) as the loss function\n",
    "* use gradient descent method to minimize the loss function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) load dataset and pre-processing\n",
    "\n",
    "### load data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv data using pandas\n",
    "admissions = pd.read_csv('binary.csv')\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-processing data\n",
    "\n",
    "* **make dummy variables for rank**\n",
    "\n",
    "(1) **pandas.get_dummies**(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "Convert categorical variable into dummy/indicator variables\n",
    "\n",
    "*Parameters*:\t\n",
    "**data** : array-like, Series, or DataFrame\n",
    "\n",
    "**prefix** : string, list of strings, or dict of strings, default None\n",
    "String to append DataFrame column names Pass a list with length equal to the number of columns when calling get_dummies on a DataFrame. Alternatively, prefix can be a dictionary mapping column names to prefixes.\n",
    "\n",
    "**prefix_sep** : string, default ‘_’\n",
    "\n",
    "*Returns*\n",
    "**dummies** : DataFrame or SparseDataFrame\n",
    "\n",
    "(2) **concatenate objects along a particular axis with optional set logic along the other axes **\n",
    "\n",
    "**pandas.concat**(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "**objs** : a sequence or mapping of Series, DataFrame, or Panel objects\n",
    "If a dict is passed, the sorted keys will be used as the keys argument, unless it is passed, in which case the values will be selected (see below). Any None objects will be dropped silently unless they are all None in which case a ValueError will be raised\n",
    "\n",
    "**axis** : {0/’index’, 1/’columns’}, default 0\n",
    "The axis to concatenate along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- print admissions['rank'] = [index, rank] ----\n",
      "0    3\n",
      "1    3\n",
      "2    1\n",
      "3    4\n",
      "4    4\n",
      "Name: rank, dtype: int64\n",
      "---- After pd.get_dummies operation -----\n",
      "   rank_1  rank_2  rank_3  rank_4\n",
      "0       0       0       1       0\n",
      "1       0       0       1       0\n",
      "2       1       0       0       0\n",
      "3       0       0       0       1\n",
      "4       0       0       0       1\n",
      "--- data after concat ----\n",
      "   admit  gre   gpa  rank  rank_1  rank_2  rank_3  rank_4\n",
      "0      0  380  3.61     3       0       0       1       0\n",
      "1      1  660  3.67     3       0       0       1       0\n",
      "2      1  800  4.00     1       1       0       0       0\n",
      "3      1  640  3.19     4       0       0       0       1\n",
      "4      0  520  2.93     4       0       0       0       1\n"
     ]
    }
   ],
   "source": [
    "# Make dummy variables for rank\n",
    "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "\n",
    "print(\"---- print admissions['rank'] = [index, rank] ----\")\n",
    "print(admissions['rank'].head())\n",
    "\n",
    "print(\"---- After pd.get_dummies operation -----\")\n",
    "print(pd.get_dummies(admissions['rank'], prefix='rank').head())\n",
    "\n",
    "print(\"--- data after concat ----\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **remove the redundant column of \"rank\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
      "0      0  380  3.61       0       0       1       0\n",
      "1      1  660  3.67       0       0       1       0\n",
      "2      1  800  4.00       1       0       0       0\n",
      "3      1  640  3.19       0       0       0       1\n",
      "4      0  520  2.93       0       0       0       1\n"
     ]
    }
   ],
   "source": [
    "data = data.drop('rank', axis=1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **standarize features - scaling **\n",
    "\n",
    "DataFrame.loc\n",
    "\n",
    "Purely label-location based indexer for selection by label.\n",
    "\n",
    ".loc[ ] is primarily label based, but may also be used with a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- before scaling ----\n",
      "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
      "0      0  380  3.61       0       0       1       0\n",
      "1      1  660  3.67       0       0       1       0\n",
      "2      1  800  4.00       1       0       0       0\n",
      "3      1  640  3.19       0       0       0       1\n",
      "4      0  520  2.93       0       0       0       1\n",
      "---- after scaling ----\n",
      "   admit       gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
      "0      0 -1.798011  0.578348       0       0       1       0\n",
      "1      1  0.625884  0.736008       0       0       1       0\n",
      "2      1  1.837832  1.603135       1       0       0       0\n",
      "3      1  0.452749 -0.525269       0       0       0       1\n",
      "4      0 -0.586063 -1.208461       0       0       0       1\n"
     ]
    }
   ],
   "source": [
    "# Standarize features\n",
    "print(\"---- before scaling ----\")\n",
    "print(data.head())\n",
    "\n",
    "for field in ['gre', 'gpa']:\n",
    "    mean, std = data[field].mean(), data[field].std()\n",
    "    #print(data[field].head())\n",
    "    #print(mean, std)\n",
    "    data.loc[:,field]  = data.loc[:,field].apply(lambda x: (x - mean) / std)\n",
    "\n",
    "print(\"---- after scaling ----\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **split off random 10% of dataset for testing **\n",
    "\n",
    "\n",
    "(1) **numpy.random.choice(a, size=None, replace=True, p=None)**\n",
    "Generates a random sample from a given 1-D array\n",
    "\n",
    "*Parameters*:\n",
    "\n",
    "**a** : 1-D array-like or int\n",
    "If an ndarray, a random sample is generated from its elements. If an int, the random sample is generated as if a were np.arange(a)\n",
    "\n",
    "**size** : int or tuple of ints, optional\n",
    "Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. Default is None, in which case a single value is returned.\n",
    "\n",
    "**replace** : boolean, optional\n",
    "Whether the sample is with or without replacement\n",
    "\n",
    "**p** : 1-D array-like, optional\n",
    "The probabilities associated with each entry in a. If not given the sample assumes a uniform distribution over all entries in a.\n",
    "\n",
    "*Returns*:\t\n",
    "**samples** : single item or ndarray; The generated random samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate index of 90% dataset randomly as training data; the rest is testing data\n",
    "sample = np.random.choice(data.index, size=int(len(data)*0.9), replace=False)\n",
    "# split data set into two subset: data is training set, and test_data is testing set\n",
    "data, test_data = data.loc[sample], data.drop(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **split into features and labels **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, targets = data.drop('admit', axis=1), data['admit']\n",
    "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) define model, loss function\n",
    "\n",
    "\n",
    "* **activation function**: sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **model**: simple linear regression model with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_records, n_features = features.shape\n",
    "# initialize weights\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) gradient descent method to minimize error\n",
    "\n",
    "** SSE ** : sum square error\n",
    "\n",
    "** MSE ** : mean square error as loss function\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html\n",
    "<img src=\"MSE.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the SSE, we're going to use the mean of the square errors (MSE). Now that we're using a lot of data, summing up all the weight steps can lead to really large updates that make the gradient descent diverge. To compensate for this, you'd need to use a quite small learning rate. Instead, we can just divide by the number of records in our data, m to take the average. This way, no matter how much data we use, our learning rates will typically be in the range of 0.01 to 0.001. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html\n",
    "<img src=\"single_layer.jpeg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train loss: ', 0.19475092849607611)\n",
      "('Train loss: ', 0.1947509281939236)\n",
      "('Train loss: ', 0.19475092816854309)\n",
      "('Train loss: ', 0.19475092816639603)\n",
      "('Train loss: ', 0.1947509281662136)\n",
      "('Train loss: ', 0.19475092816619818)\n",
      "('Train loss: ', 0.1947509281661969)\n",
      "('Train loss: ', 0.19475092816619674)\n",
      "('Train loss: ', 0.19475092816619657)\n",
      "('Train loss: ', 0.1947509281661967)\n"
     ]
    }
   ],
   "source": [
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 2\n",
    "last_loss = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    # set weight step (or change/delta) to zero\n",
    "    del_w = np.zeros(weights.shape)\n",
    "\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # loop through all records, x is input, y is label\n",
    "        output = sigmoid(np.dot(x, weights))\n",
    "        # calculate output error\n",
    "        error = y - output\n",
    "        # calculate update on weights\n",
    "        del_w += error * output * ( 1 - output ) * x\n",
    "    # Update the weights here. The learning rate times the \n",
    "    # change in weights, divided by the number of records to average\n",
    "    weights += learnrate * del_w / n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        # put training data into the network -> go through activation function to get output\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        # calculate MSE as loss function\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        print(\"Train loss: \", loss)\n",
    "        last_loss = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) calculate accuracy on testing dataset\n",
    "\n",
    "assume accuracy > 0.5 is good. That means our model should predict correctly on 50% samples of the testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
